{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d7badec",
   "metadata": {},
   "source": [
    "<h1> Emojify! </h1>\n",
    "\n",
    "<h2> Input: where is the food </h2>\n",
    "\n",
    "<h2> Output: where is the food üç¥</h2>\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p> 1. We'll use the <b>emoji</b> package to help display emoticons.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce18ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install emoji\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b05998",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 2. Import relevant libraries. The <b>emo_utils</b> library has some useful functions for this exercise, such as mapping integers to emoticons. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad731dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbcbc3a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 3. Using <b>label_to_emoji(idx)</b> to map integers to emoticons. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e216b9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t ‚ù§Ô∏è \n",
      "\n",
      "1 \t ‚öæ \n",
      "\n",
      "2 \t üòÑ \n",
      "\n",
      "3 \t :disappointed: \n",
      "\n",
      "4 \t üç¥ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "    print(idx,'\\t',label_to_emoji(idx),'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab6ee6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 4. <b>train.csv</b> contains some training sentences. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3781a231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 2) \n",
      "\n",
      "never talk to me again 3 :disappointed:\n",
      "I am proud of your achievements 2 üòÑ\n",
      "It is the worst day in my life 3 :disappointed:\n",
      "Miss you so much 0 ‚ù§Ô∏è\n",
      "food is life 4 üç¥\n",
      "I love you mum 0 ‚ù§Ô∏è\n",
      "Stop saying bullshit 3 :disappointed:\n",
      "congratulations on your acceptance 2 üòÑ\n",
      "The assignment is too long 3 :disappointed:\n",
      "I want to go play 1 ‚öæ\n"
     ]
    }
   ],
   "source": [
    "train_data = np.array(pd.read_csv('train.csv', header=None, index_col=False))\n",
    "print(train_data.shape,'\\n')\n",
    "\n",
    "X_train, Y_train = train_data[:,0], train_data[:,1]\n",
    "Y_train = np.array(Y_train, dtype=int)\n",
    "\n",
    "for idx in range(10):\n",
    "    print(X_train[idx], Y_train[idx], label_to_emoji(Y_train[idx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448b8018",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 5. <b>test.csv</b> contains some test sentences. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "627d35cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 2)\n",
      "I want to eat 4 üç¥\n",
      "he did not answer 3 :disappointed:\n",
      "he got a very nice raise 2 üòÑ\n",
      "she got me a nice present 2 üòÑ\n",
      "ha ha ha it was so funny 2 üòÑ\n",
      "he is a good friend 2 üòÑ\n",
      "I am upset 3 :disappointed:\n",
      "We had such a lovely dinner tonight 2 üòÑ\n",
      "where is the food 4 üç¥\n",
      "Stop making this joke ha ha ha 2 üòÑ\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array(pd.read_csv('test.csv', header=None, index_col=False))\n",
    "print(test_data.shape)\n",
    "\n",
    "X_test, Y_test = test_data[:,0], test_data[:,1]\n",
    "Y_test = np.array(Y_test, dtype=int)\n",
    "\n",
    "for idx in range(10):\n",
    "    print(X_test[idx], Y_test[idx], label_to_emoji(Y_test[idx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e92917",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "6. <b>glove.6B.50d.txt</b> contains 50-dimensional GloVe embeddings for some common english words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d67eae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632bd157",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 7. An example of mapping a word to its unique index, and obtaining its GloVe embedding. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ec8e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of cucumber in the vocabulary is: 113317 \n",
      "\n",
      "GloVe of cucumber is:\n",
      " [ 0.68224  -0.31608  -0.95201   0.47108   0.56571   0.13151   0.22457\n",
      "  0.094995 -1.3237   -0.51545  -0.39337   0.88488   0.93826   0.22931\n",
      "  0.088624 -0.53908   0.23396   0.73245  -0.019123 -0.26552  -0.40433\n",
      " -1.5832    1.1316    0.4419   -0.48218   0.4828    0.14938   1.1245\n",
      "  1.0159   -0.50213   0.83831  -0.31303   0.083242  1.7161    0.15024\n",
      "  1.0324   -1.5005    0.62348   0.54508  -0.88484   0.53279  -0.085119\n",
      "  0.02141  -0.56629   1.1463    0.6464    0.78318  -0.067662  0.22884\n",
      " -0.042453]\n",
      "\n",
      "the 289845th word in the vocabulary is potatoes\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "print(\"the index of\", word, \"in the vocabulary is:\", word_to_index[word],'\\n')\n",
    "print('GloVe of', word, \"is:\\n\", word_to_vec_map[word])\n",
    "\n",
    "index = 289845\n",
    "print(\"\\nthe\", str(index) + \"th word in the vocabulary is\", index_to_word[index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca25ae1",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 8. Create a dataset to train in PyTorch. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76fb80ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([185457., 383068., 360915., 163237., 286375.,      0.,      0.,\n",
      "            0.,      0.,      0.]), 1)\n"
     ]
    }
   ],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    for i in range(m):\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            X_indices[i, j] = int(word_to_index[w])\n",
    "            j = j + 1\n",
    "    return X_indices\n",
    "\n",
    "\n",
    "class emojiDataset(Data.Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train\n",
    "        traindata,trainlabels = read_csv(os.path.join(self.root,'train.csv'))\n",
    "        self.train_data = sentences_to_indices(traindata, word_to_index, 10)\n",
    "        self.train_labels = trainlabels\n",
    "        # self.train_labels = convert_to_one_hot(trainlabels, C=5)\n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            data, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            pass\n",
    "        if self.transform is not None:\n",
    "            pass\n",
    "        if self.target_transform is not None:\n",
    "            pass\n",
    "        return data, target\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return 132\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "train_data = emojiDataset(\n",
    "    root='./',\n",
    ")\n",
    "print(train_data[9])\n",
    "\n",
    "# train_loader = Data.DataLoader(dataset=train_data, batch_size=20, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faced-affiliation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([185457.,  52943., 293982., 268046., 394565.,  45460.,      0.,\n",
       "             0.,      0.,      0.]),\n",
       " 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "enormous-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=20, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "alive-rwanda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 10]) torch.Size([20])\n",
      "tensor([[170403., 170403., 170403., 193716., 383514., 336114., 155345.,      0.,\n",
      "              0.,      0.],\n",
      "        [185457., 225979., 254258., 382713.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [185457., 387696.,  94875., 337662.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [175199.,  90548., 264550., 126552.,  57189.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [185457.,  52943., 293982., 268046., 394565.,  45460.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [220930., 174642., 151204., 361190.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [166369., 198213.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [185457.,  52943., 377946., 124906.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [185457.,  52943., 271178., 151204.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [386887., 192973., 394565., 145839., 286410.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [327864., 123517., 264550.,  56160., 254258., 356822.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [361940.,  65963., 357212., 394475., 385664., 264550., 177231.,      0.,\n",
      "              0.,      0.],\n",
      "        [376819.,  58997., 175409.,      0.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [358160., 192973., 336114., 155345.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [185457., 164934., 183958.,  88126., 254258., 333051.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [185457., 226278., 394475.,      0.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [182540., 233708., 287518., 123517., 175199., 321938.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [182540., 117064., 394475.,  61257., 357212.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [327864., 335369.,  43010., 225985.,      0.,      0.,      0.,      0.,\n",
      "              0.,      0.],\n",
      "        [126552., 394475., 383068., 360915., 198476., 239105., 151349., 124461.,\n",
      "              0.,      0.]], dtype=torch.float64)\n",
      "tensor([2, 3, 2, 3, 2, 4, 2, 3, 4, 1, 3, 3, 4, 2, 3, 0, 1, 3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    t, l = data\n",
    "    print(t.shape, l.shape)\n",
    "    print(t)\n",
    "    print(l)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-cooling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46b406a8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 9. Create an embedding layer to obtain GloVe embeddings. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2887abbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400001, 50)\n"
     ]
    }
   ],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1  #word index begin with 1,plus 1 for padding 0\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "    return emb_matrix\n",
    "\n",
    "emb_matrix = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "print(emb_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e54ca",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 10. Define the network: </p>\n",
    "\n",
    "<img src=\"img_lstm_network.png\">\n",
    "\n",
    "<p> (image source: https://github.com/Kulbear/deep-learning-coursera) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "productive-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, 2)\n",
    "\n",
    "#input_size ‚Äì The number of expected features in the input x\n",
    "#hidden_size ‚Äì The number of features in the hidden state h\n",
    "#num_layers ‚Äì Number of recurrent layers. E.g., \n",
    "#setting num_layers=2 would mean stacking two LSTMs together \n",
    "#to form a stacked LSTM, with the second LSTM taking in outputs of \n",
    "#the first LSTM and computing the final results. Default: 1\n",
    "\n",
    "input = torch.randn(5, 3, 10)\n",
    "output = rnn(input)\n",
    "output[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cognitive-albert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.RNN(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "output = rnn(input)\n",
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "worth-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.GRU(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "output = rnn(input)\n",
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ad5177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_dim,pretrained_weight):\n",
    "        super(myModel,self).__init__()\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        pretrained_weight = np.array(pretrained_weight)\n",
    "        self.word_embeds.weight.data.copy_(torch.from_numpy(pretrained_weight))\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, 128, 2,batch_first=True,dropout=0.5)\n",
    "        self.linear = nn.Linear(128,5)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.word_embeds(x)\n",
    "        out, _ = self.rnn(out)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.linear(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20136d04",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 11. Create the network: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b8a048a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myModel(\n",
       "  (word_embeds): Embedding(400001, 50)\n",
       "  (rnn): LSTM(50, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (linear): Linear(in_features=128, out_features=5, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len = len(word_to_index) + 1\n",
    "model = myModel(vocab_len,50,emb_matrix)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2242ac89",
   "metadata": {},
   "source": [
    "<p> 12. Define the loss function and the optimizers. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08713e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer1 = torch.optim.Adam(model.rnn.parameters(),lr=0.001)\n",
    "optimizer2 = torch.optim.Adam(model.linear.parameters(),lr=0.001)\n",
    "\n",
    "# optimizer2 = torch.optim.Adam(list(model.linear.parameters()+model.rnn.parameters()),lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-cooling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dab50dc",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 13. Start the training process.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "989bf7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 loss: 11.234149813652039\n",
      "epoch:  10 loss: 9.901391863822937\n",
      "epoch:  20 loss: 8.536113023757935\n",
      "epoch:  30 loss: 7.464289963245392\n",
      "epoch:  40 loss: 7.493804454803467\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    for step,(data,target) in enumerate(train_loader):\n",
    "        data = data.long()\n",
    "        target = target.long()\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        input = Variable(data).to(device)\n",
    "        target = Variable(target).to(device)\n",
    "        \n",
    "        output = model(input)\n",
    "        \n",
    "        loss = loss_func(output,target)\n",
    "        \n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "        \n",
    "    if epoch%10 == 0:\n",
    "        print('epoch: ', epoch, 'loss:', total_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0668212",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 14. Test the trained network. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceeb69c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " prediction: I want to eatüç¥\n",
      " prediction: he did not answer:disappointed:\n",
      " prediction: he got a very nice raiseüç¥\n",
      " prediction: she got me a nice present‚ù§Ô∏è\n",
      " prediction: ha ha ha it was so funnyüòÑ\n",
      " prediction: he is a good friend‚ù§Ô∏è\n",
      " prediction: I am upset:disappointed:\n",
      " prediction: We had such a lovely dinner tonightüç¥\n",
      " prediction: where is the foodüç¥\n",
      " prediction: Stop making this joke ha ha haüòÑ\n",
      " prediction: where is the ball‚öæ\n",
      " prediction: work is hardüòÑ\n",
      " prediction: This girl is messing with me‚ù§Ô∏è\n",
      " prediction: are you serious:disappointed:\n",
      " prediction: Let us go play baseball‚öæ\n",
      " prediction: This stupid grader is not working:disappointed:\n",
      " prediction: work is horrible:disappointed:\n",
      " prediction: Congratulation for having a babyüòÑ\n",
      " prediction: stop pissing me off:disappointed:\n",
      " prediction: any suggestions for dinnerüç¥\n",
      " prediction: I love taking breaks:disappointed:\n",
      " prediction: you brighten my day‚ù§Ô∏è\n",
      " prediction: I boiled riceüç¥\n",
      " prediction: she is a bully‚ù§Ô∏è\n",
      " prediction: Why are you feeling bad:disappointed:\n",
      " prediction: I am upset:disappointed:\n",
      " prediction: give me the ball‚öæ\n",
      " prediction: My grandmother is the love of my life‚ù§Ô∏è\n",
      " prediction: enjoy your game‚öæ\n",
      " prediction: valentine day is nearüòÑ\n",
      " prediction: I miss you so much‚ù§Ô∏è\n",
      " prediction: throw the ball‚öæ\n",
      " prediction: My life is so boring:disappointed:\n",
      " prediction: she said yesüòÑ\n",
      " prediction: will you be my valentine‚ù§Ô∏è\n",
      " prediction: he can pitch really well‚öæ\n",
      " prediction: dance with meüòÑ\n",
      " prediction: I am hungry‚ù§Ô∏è\n",
      " prediction: See you at the restaurantüç¥\n",
      " prediction: I like to laughüòÑ\n",
      " prediction: I will run‚öæ\n",
      " prediction: I like your jacket‚ù§Ô∏è\n",
      " prediction: i miss her‚ù§Ô∏è\n",
      " prediction: what is your favorite baseball game‚öæ\n",
      " prediction: Good jobüòÑ\n",
      " prediction: I love you to the stars and back‚ù§Ô∏è\n",
      " prediction: What you did was awesomeüòÑ\n",
      " prediction: ha ha ha lolüòÑ\n",
      " prediction: I do not want to joke‚ù§Ô∏è\n",
      " prediction: go away:disappointed:\n",
      " prediction: yesterday we lost again:disappointed:\n",
      " prediction: family is all I have‚ù§Ô∏è\n",
      " prediction: you are failing this exercise:disappointed:\n",
      " prediction: Good jokeüòÑ\n",
      " prediction: You deserve this nice prize‚ù§Ô∏è\n",
      " prediction: I did not have breakfastüç¥\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, 10)\n",
    "X_test_indices = torch.from_numpy(X_test_indices)\n",
    "X_test_indices = Variable(X_test_indices.long()).to(device)\n",
    "pred = model(X_test_indices)\n",
    "# print(pred)\n",
    "num = np.zeros((X_test.shape[0]), dtype=int)\n",
    "for i in range(len(X_test)):\n",
    "    num[i] = np.argmax(pred.data[i].detach().cpu().numpy())\n",
    "    print(' prediction: ' + X_test[i] + label_to_emoji(num[i]).strip())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b159649",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<p> 15. Contingency Matrix of class-wise accuracy </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8e6806a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ‚ù§Ô∏è    ‚öæ    üòÑ    :disappointed:   üç¥\n",
      "Predicted   0  1   2   3  4  All\n",
      "Actual                          \n",
      "0           6  0   0   1  0    7\n",
      "1           0  8   0   0  0    8\n",
      "2           5  0  11   0  2   18\n",
      "3           3  0   1  12  0   16\n",
      "4           1  0   0   0  6    7\n",
      "All        15  8  12  13  8   56\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
    "print(pd.crosstab(Y_test, num.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "plot_confusion_matrix(Y_test, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a81c633",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<br>\n",
    "\n",
    "References:\n",
    "\n",
    "https://github.com/Kulbear/deep-learning-coursera\n",
    "\n",
    "https://github.com/sushantdhumak/Emojify\n",
    "\n",
    "https://github.com/cryer/emojify-pyTorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
